{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import errno\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import cv2\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "PATH_TO_DATASET = 'fer2013.csv'\n",
    "DATASET_FOLDER = 'dataset'\n",
    "IMAGE_FOLDER = 'images'\n",
    "IMAGE_HEIGHT = 48\n",
    "IMAGE_WIDTH = 48\n",
    "PATH_TO_PREDICTOR = 'shape_predictor_68_face_landmarks.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "dict_images = {'Training':[], 'PublicTest':[], 'PrivateTest':[]}\n",
    "dict_labels = {'Training':[], 'PublicTest':[], 'PrivateTest':[]}\n",
    "dict_landmarks = {'Training':[], 'PublicTest':[], 'PrivateTest':[]}\n",
    "predictor = dlib.shape_predictor(PATH_TO_PREDICTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from csv into memory\n",
    "data = pd.read_csv(PATH_TO_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       emotion                                             pixels        Usage\n",
      "0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...     Training\n",
      "1            0  151 150 147 155 148 133 111 140 170 174 182 15...     Training\n",
      "2            2  231 212 156 164 174 138 161 173 182 200 106 38...     Training\n",
      "3            4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...     Training\n",
      "4            6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...     Training\n",
      "5            2  55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...     Training\n",
      "6            4  20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...     Training\n",
      "7            3  77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...     Training\n",
      "8            3  85 84 90 121 101 102 133 153 153 169 177 189 1...     Training\n",
      "9            2  255 254 255 254 254 179 122 107 95 124 149 150...     Training\n",
      "10           0  30 24 21 23 25 25 49 67 84 103 120 125 130 139...     Training\n",
      "11           6  39 75 78 58 58 45 49 48 103 156 81 45 41 38 49...     Training\n",
      "12           6  219 213 206 202 209 217 216 215 219 218 223 23...     Training\n",
      "13           6  148 144 130 129 119 122 129 131 139 153 140 12...     Training\n",
      "14           3  4 2 13 41 56 62 67 87 95 62 65 70 80 107 127 1...     Training\n",
      "15           5  107 107 109 109 109 109 110 101 123 140 144 14...     Training\n",
      "16           3  14 14 18 28 27 22 21 30 42 61 77 86 88 95 100 ...     Training\n",
      "17           2  255 255 255 255 255 255 255 255 255 255 255 25...     Training\n",
      "18           6  134 124 167 180 197 194 203 210 204 203 209 20...     Training\n",
      "19           4  219 192 179 148 208 254 192 98 121 103 145 185...     Training\n",
      "20           4  1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 7 12 23 45 38 ...     Training\n",
      "21           2  174 51 37 37 38 41 22 25 22 24 35 51 70 83 98 ...     Training\n",
      "22           0  123 125 124 142 209 226 234 236 231 232 235 22...     Training\n",
      "23           0  8 9 14 21 26 32 37 46 52 62 72 70 71 73 76 83 ...     Training\n",
      "24           3  252 250 246 229 182 140 98 72 53 44 67 95 95 8...     Training\n",
      "25           3  224 227 219 217 215 210 187 177 189 200 206 21...     Training\n",
      "26           5  162 200 187 180 197 198 196 192 176 152 136 11...     Training\n",
      "27           0  236 230 225 226 228 209 199 193 196 211 199 19...     Training\n",
      "28           3  210 210 210 210 211 207 147 103 68 60 47 70 12...     Training\n",
      "29           5  50 44 74 141 187 187 169 113 80 128 181 172 76...     Training\n",
      "...        ...                                                ...          ...\n",
      "35857        5  253 255 229 150 89 61 54 60 55 49 61 50 56 45 ...  PrivateTest\n",
      "35858        4  11 11 11 13 20 27 38 41 38 34 20 13 10 39 85 1...  PrivateTest\n",
      "35859        4  11 13 16 27 24 26 89 161 190 197 201 206 210 2...  PrivateTest\n",
      "35860        3  27 42 62 91 112 118 122 123 119 124 129 131 13...  PrivateTest\n",
      "35861        6  233 232 208 188 194 179 177 167 157 180 185 19...  PrivateTest\n",
      "35862        2  73 54 63 76 82 71 67 69 73 72 92 98 117 119 14...  PrivateTest\n",
      "35863        5  196 196 197 197 198 198 198 196 176 148 122 10...  PrivateTest\n",
      "35864        4  68 59 65 78 118 131 137 141 142 135 135 137 13...  PrivateTest\n",
      "35865        3  102 109 109 106 104 107 112 109 116 119 117 12...  PrivateTest\n",
      "35866        6  87 82 59 61 72 102 143 130 90 95 143 173 146 1...  PrivateTest\n",
      "35867        3  198 198 197 196 196 197 196 196 196 195 196 18...  PrivateTest\n",
      "35868        2  204 209 215 218 214 214 214 217 205 175 170 16...  PrivateTest\n",
      "35869        3  217 220 222 223 223 224 225 223 223 225 223 22...  PrivateTest\n",
      "35870        2  6 8 4 5 30 48 61 70 76 79 98 117 130 137 143 1...  PrivateTest\n",
      "35871        6  112 102 98 89 98 133 164 185 180 179 185 169 1...  PrivateTest\n",
      "35872        5  131 159 90 59 10 0 1 1 1 0 1 1 0 0 2 2 5 7 9 1...  PrivateTest\n",
      "35873        4  54 57 77 122 121 76 73 80 58 22 26 27 35 41 66...  PrivateTest\n",
      "35874        5  43 43 51 73 94 97 102 95 99 107 126 144 154 17...  PrivateTest\n",
      "35875        5  248 251 239 144 102 95 82 77 91 138 153 145 14...  PrivateTest\n",
      "35876        6  29 29 27 31 49 56 29 19 22 20 34 43 55 71 85 9...  PrivateTest\n",
      "35877        6  139 143 145 154 159 168 176 181 190 191 195 19...  PrivateTest\n",
      "35878        3  0 39 81 80 104 97 51 64 68 46 41 67 53 68 70 5...  PrivateTest\n",
      "35879        2  0 0 6 16 19 31 47 18 26 19 17 8 15 3 4 2 14 20...  PrivateTest\n",
      "35880        2  164 172 175 171 172 173 178 181 188 192 197 20...  PrivateTest\n",
      "35881        0  181 177 176 156 178 144 136 132 122 107 131 16...  PrivateTest\n",
      "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n",
      "35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n",
      "35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n",
      "35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n",
      "35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest\n",
      "\n",
      "[35887 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# print dataset\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current usage: Training\n",
      "Current usage: PublicTest\n",
      "Current usage: PrivateTest\n",
      "Current emotion: 0\n",
      "Current emotion: 2\n",
      "Current emotion: 4\n",
      "Current emotion: 6\n",
      "Current emotion: 3\n",
      "Current emotion: 5\n",
      "Current emotion: 1\n"
     ]
    }
   ],
   "source": [
    "# create folder structure\n",
    "# Usages\n",
    "for usage in data['Usage'].unique():\n",
    "    print(\"Current usage: \" + usage)\n",
    "    if not os.path.exists(DATASET_FOLDER + '/' + usage):\n",
    "        try:\n",
    "            os.makedirs(DATASET_FOLDER + '/' + usage)\n",
    "        except OSError as exception:\n",
    "            if exception.errno == errno.EEXIST:\n",
    "                pass\n",
    "            else:\n",
    "                raise\n",
    "                \n",
    "# Images\n",
    "for emotion in data['emotion'].unique():\n",
    "    print(\"Current emotion: \" + str(emotion))\n",
    "    if not os.path.exists(DATASET_FOLDER + '/' + IMAGE_FOLDER + '/' + str(emotion)):\n",
    "        try:\n",
    "            os.makedirs(DATASET_FOLDER + '/' + IMAGE_FOLDER + '/' + str(emotion))\n",
    "        except OSError as exception:\n",
    "            if exception.errno == errno.EEXIST:\n",
    "                pass\n",
    "            else:\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding; 7 = 7 emotions\n",
    "# emotion 2 = [0, 0, 1, 0, 0, 0, 0]\n",
    "# emotion 4 = [0, 0, 0, 0, 1, 0, 0]\n",
    "def one_hot_encoding(emotion):\n",
    "    label = list(np.zeros(7, 'uint8'))\n",
    "    label[emotion] = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract landmarks from face, if not exactly one face skip\n",
    "def get_landmarks(image, faces):\n",
    "    if len(faces) > 1:\n",
    "        print(\"FoundTooManyFaces\")\n",
    "        raise BaseException(\"FoundTooManyFaces\")\n",
    "    if len(faces) == 0:\n",
    "        print(\"FoundNoFace\")\n",
    "        raise BaseException(\"FoundNoFace\")\n",
    "    \n",
    "    return np.matrix([[landmark.x, landmark.y] for landmark in predictor(image, faces[0]).parts()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jay\\anaconda3\\envs\\facialexpr\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# image counter\n",
    "image_number = 0\n",
    "# convert pixels from csv to image, save labels = emotions and landmarks\n",
    "for index, row in data.iterrows():\n",
    "    emotion, pixels, usage = row\n",
    "    \n",
    "    # pixels into numpy array and reshape\n",
    "    image = np.fromstring(pixels, dtype=int, sep=\" \").reshape((IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        \n",
    "    # save image\n",
    "    image_path = DATASET_FOLDER + '/' + IMAGE_FOLDER + '/' + str(emotion) + '/' + str(image_number) + '.jpg'\n",
    "    image_number = image_number + 1\n",
    "    scipy.misc.imsave(image_path, image)\n",
    "    \n",
    "    # emotion one hot encoding to label\n",
    "    one_hot = one_hot_encoding(emotion)\n",
    "    \n",
    "    \n",
    "    # extract landmarks from image\n",
    "    image_jpg = cv2.imread(image_path)\n",
    "    faces = [dlib.rectangle(left=1, top=1, right=47, bottom=47)]\n",
    "    landmarks = get_landmarks(image_jpg, faces)\n",
    "    \n",
    "    # add everything to their arrays\n",
    "    dict_images[usage].append(image)\n",
    "    dict_labels[usage].append(one_hot)\n",
    "    dict_landmarks[usage].append(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save np arrays for learning\n",
    "# training data\n",
    "current_set = 'Training'\n",
    "current_folder = DATASET_FOLDER + '/' + current_set + '/'\n",
    "np.save(current_folder + 'images.npy', dict_images[current_set])\n",
    "np.save(current_folder + 'labels.npy', dict_labels[current_set])\n",
    "np.save(current_folder + 'landmarks.npy', dict_landmarks[current_set])\n",
    "# public test data\n",
    "current_set = 'PublicTest'\n",
    "current_folder = DATASET_FOLDER + '/' + current_set + '/'\n",
    "np.save(current_folder + 'images.npy', dict_images[current_set])\n",
    "np.save(current_folder + 'labels.npy', dict_labels[current_set])\n",
    "np.save(current_folder + 'landmarks.npy', dict_landmarks[current_set])\n",
    "# private test data\n",
    "current_set = 'PrivateTest'\n",
    "current_folder = DATASET_FOLDER + '/' + current_set + '/'\n",
    "np.save(current_folder + 'images.npy', dict_images[current_set])\n",
    "np.save(current_folder + 'labels.npy', dict_labels[current_set])\n",
    "np.save(current_folder + 'landmarks.npy', dict_landmarks[current_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
